{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepER_AirBnB.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHyBi-cvkDjU"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RSCxA8aMGCF",
        "outputId": "cff10753-13f9-4f67-d9e3-676a356bc8ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPODXcdyIdfW"
      },
      "source": [
        "import io\r\n",
        "from google.colab import files\r\n",
        "from google.colab import drive\r\n",
        "import sys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1rMFsNvNHO4"
      },
      "source": [
        "sys.path.insert(0,'/content/drive/My Drive/CERTA/models')\r\n",
        "sys.path.insert(0,'/content/drive/My Drive/CERTA/certa')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Bp59T7NJuF"
      },
      "source": [
        "import DeepER as dp\r\n",
        "import eval\r\n",
        "import os\r\n",
        "from local_explain import find_thresholds\r\n",
        "from local_explain import dataset_local\r\n",
        "from triangles_method import explainSamples\r\n",
        "from eval import expl_eval\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import gensim.downloader as api"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPLP9brOkKFP"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2Lt8c3kNWIg"
      },
      "source": [
        "def to_deeper_data(df: pd.DataFrame):\r\n",
        "    res = []\r\n",
        "    for r in range(len(df)):\r\n",
        "        row = df.iloc[r]\r\n",
        "        lpd = row.filter(regex='^ltable_')\r\n",
        "        rpd = row.filter(regex='^rtable_')\r\n",
        "        if 'label' in row:\r\n",
        "            label = row['label']\r\n",
        "            res.append((lpd.values.astype('str'), rpd.values.astype('str'), label))\r\n",
        "        else:\r\n",
        "            res.append((lpd.values.astype('str'), rpd.values.astype('str')))\r\n",
        "    return res"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV3m5dgzOJtb"
      },
      "source": [
        "def change_prefix_for_deeper(df: pd.DataFrame):\r\n",
        "  lprefix = 'ltable_'\r\n",
        "  rprefix = 'rtable_'\r\n",
        "  columns = df.columns\r\n",
        "  new_names = {}\r\n",
        "  for col_name in columns:\r\n",
        "    if col_name != \"id\" or col_name != \"label\":\r\n",
        "      if col_name[0:5] == \"left_\":\r\n",
        "        new_name = lprefix + col_name[5:]\r\n",
        "      else:\r\n",
        "        new_name = rprefix + col_name[6:]\r\n",
        "        \r\n",
        "      new_names[col_name] = new_name\r\n",
        "  \r\n",
        "  new_names[\"id\"] = \"id\"\r\n",
        "  new_names[\"label\"] = \"label\"\r\n",
        "  df = df.rename(columns=new_names)\r\n",
        "  return df"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpWAOh9SRDwe"
      },
      "source": [
        "train = pd.read_csv('trainRM.csv')\r\n",
        "valid = pd.read_csv('validationRM.csv')\r\n",
        "test = pd.read_csv('testRM.csv')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSeraLjxRfyJ",
        "outputId": "2025cea2-7a43-4717-b761-4471ab61c42f"
      },
      "source": [
        "train = change_prefix_for_deeper(train)\r\n",
        "valid = change_prefix_for_deeper(valid)\r\n",
        "test = change_prefix_for_deeper(test)\r\n",
        "test.columns"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'label', 'ltable_id', 'ltable_name', 'ltable_host_id',\n",
              "       'ltable_host_name', 'ltable_neighbourhood_group',\n",
              "       'ltable_neighbourhood', 'ltable_latitude', 'ltable_longitude',\n",
              "       'ltable_room_type', 'ltable_price', 'ltable_minimum_nights',\n",
              "       'ltable_number_of_reviews', 'ltable_last_review',\n",
              "       'ltable_reviews_per_month', 'ltable_calculated_host_listings_count',\n",
              "       'ltable_availability_365', 'rtable_id', 'rtable_name', 'rtable_host_id',\n",
              "       'rtable_host_name', 'rtable_neighbourhood_group',\n",
              "       'rtable_neighbourhood', 'rtable_latitude', 'rtable_longitude',\n",
              "       'rtable_room_type', 'rtable_price', 'rtable_minimum_nights',\n",
              "       'rtable_number_of_reviews', 'rtable_last_review',\n",
              "       'rtable_reviews_per_month', 'rtable_calculated_host_listings_count',\n",
              "       'rtable_availability_365'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB8oSkAekVsQ"
      },
      "source": [
        "# Load embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYvPkKEESbnJ"
      },
      "source": [
        "if not os.path.exists('glove.6B.50d.txt'):\r\n",
        "    word_vectors = api.load(\"glove-wiki-gigaword-50\")\r\n",
        "    word_vectors.save_word2vec_format('glove.6B.50d.txt', binary=False)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL3FbXr6SlUP",
        "outputId": "b7765843-e0ff-4c43-842e-7ec4b16de910"
      },
      "source": [
        "embeddings_index = dp.init_embeddings_index('glove.6B.50d.txt')\r\n",
        "emb_dim = len(embeddings_index['cat'])\r\n",
        "embeddings_model, tokenizer = dp.init_embeddings_model(embeddings_index)\r\n",
        "model = dp.init_DeepER_model(emb_dim)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* Costruzione indice degli embeddings.....Fatto. 400001 embeddings totali.\n",
            "* Creazione del modello per il calcolo degli embeddings....\n",
            "* Inizializzo il tokenizzatore.....Fatto: 400001 parole totali.\n",
            "* Preparazione della matrice di embedding.....Fatto. Dimensioni matrice embeddings: (400002, 50)\n",
            "\n",
            "°°° EMBEDDING MODEL °°°\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Tupla_A (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Tupla_B (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding_lookup (Embedding)    (None, None, 50)     20000100    Tupla_A[0][0]                    \n",
            "                                                                 Tupla_B[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 20,000,100\n",
            "Trainable params: 0\n",
            "Non-trainable params: 20,000,100\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            "°°° DeepER Model °°°\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpF80X5jka6r"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is8VEtNlSt25"
      },
      "source": [
        "model = dp.train_model_ER(to_deeper_data(train), model, embeddings_model, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrAcawx7kenI"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m15woxNSkju4"
      },
      "source": [
        "Testing on Rome's test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yNd3fcuaY8Q",
        "outputId": "a06ba040-f550-4454-d1e3-d5d23a0f031d"
      },
      "source": [
        "dp.model_statistics(to_deeper_data(test), model, embeddings_model, tokenizer)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* Avvio test metriche....\n",
            "-- Corpus size: 3997\n",
            "-- Non Match: 3189\n",
            "-- Match: 808\n",
            "* Preparazione input......Fatto. 3997 tuple totali, esempio label: 0 -> [1. 0.], Table1 shape: (3997, 28), Table2 shape: (3997, 28)\n",
            "* Evaluating: ===========|\n",
            "Precision: 0.9744245524296675, Recall: 0.943069306930693, f1-score: 0.9584905660377359\n",
            "Total retrieved: 782, retrieved/total matches: 762/808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9744245524296675, 0.943069306930693, 0.9584905660377359)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut3l2p9AknAG"
      },
      "source": [
        "Testing on Amsterdam's test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j21_QkvlcGBS"
      },
      "source": [
        "test = pd.read_csv('testAMS.csv')\r\n",
        "test = change_prefix_for_deeper(test)           "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN4pbW3vcYzU",
        "outputId": "91bcb169-cc77-4e97-fda1-360b56998e4b"
      },
      "source": [
        "dp.model_statistics(to_deeper_data(test), model, embeddings_model, tokenizer)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* Avvio test metriche....\n",
            "-- Corpus size: 1057\n",
            "-- Non Match: 890\n",
            "-- Match: 167\n",
            "* Preparazione input......Fatto. 1057 tuple totali, esempio label: 0 -> [1. 0.], Table1 shape: (1057, 24), Table2 shape: (1057, 22)\n",
            "* Evaluating: ===========|\n",
            "Precision: 0.5035971223021583, Recall: 0.8383233532934131, f1-score: 0.6292134831460674\n",
            "Total retrieved: 278, retrieved/total matches: 140/167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5035971223021583, 0.8383233532934131, 0.6292134831460674)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuDktULXks-v"
      },
      "source": [
        "Testing on Bergamo's test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMxkxiTjdJZO"
      },
      "source": [
        "test = pd.read_csv('testBER.csv')\r\n",
        "test = change_prefix_for_deeper(test)  "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIt0nHqadMkm",
        "outputId": "d0a20588-bb95-4d65-ab17-6809530a92af"
      },
      "source": [
        "dp.model_statistics(to_deeper_data(test), model, embeddings_model, tokenizer)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* Avvio test metriche....\n",
            "-- Corpus size: 49\n",
            "-- Non Match: 8\n",
            "-- Match: 41\n",
            "* Preparazione input......Fatto. 49 tuple totali, esempio label: 1 -> [0. 1.], Table1 shape: (49, 20), Table2 shape: (49, 20)\n",
            "* Evaluating: =============|\n",
            "Precision: 0.8, Recall: 0.5853658536585366, f1-score: 0.676056338028169\n",
            "Total retrieved: 30, retrieved/total matches: 24/41\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8, 0.5853658536585366, 0.676056338028169)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}